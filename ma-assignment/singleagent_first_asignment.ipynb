{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_dataset_builder\n",
    "ds = load_dataset(\"lukaemon/bbh\", \"causal_judgement\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_builder = load_dataset_builder(\"lukaemon/bbh\", \"causal_judgement\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BBH focuses on a suite of 23 challenging BIG-Bench tasks which we call BIG-Bench Hard (BBH). These are the task for which prior language model evaluations did not outperform the average human-rater. We find that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average humanrater performance on 10 of the 23 tasks, and Codex (code-davinci-002) to surpass the average human-rater performance on 17 of the 23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot prompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al., 2022), substantially underestimates the best performance and capabilities of language models, which is better captured via CoT prompting. As further analysis, we explore the interaction between CoT and model scale on BBH, finding that CoT enables emergent task performance on several BBH tasks with otherwise flat scaling curves.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': Value(dtype='string', id=None),\n",
       " 'target': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would a typical person answer each of the following questions about causation?\n",
      "A machine is set up in such a way that it will short circuit if both the black wire and the red wire touch the battery at the same time. The machine will not short circuit if just one of these wires touches the battery. The black wire is designated as the one that is supposed to touch the battery, while the red wire is supposed to remain in some other part of the machine. One day, the black wire and the red wire both end up touching the battery at the same time. There is a short circuit. Did the black wire cause the short circuit?\n",
      "Options:\n",
      "- Yes\n",
      "- No\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "print(ds['test'][0]['input'])\n",
    "print(ds['test'][0]['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "Answer questions about causal attribution.\n",
    "\n",
    "Q: How would a typical person answer each of the following questions about causation?\n",
    "Frank T., had an ongoing dispute with his neighbor over a stretch of land and one day decided to shoot his neighbor in the body. Frank T. had no experience with guns, his hand slipped on the barrel of the gun, and the shot went wild. Nonetheless, the bullet bounced off a large boulder several feet away and hit the neighbor's body, causing significant injury. Did Frank T. intentionally shoot his neighbor in the body?\n",
    "Options:\n",
    "- Yes\n",
    "- No\n",
    "A: Let's think step by step.\n",
    "Here in this question, we are told that \"Frank T. had no experience with guns, his hand slipped on the barrel of the gun, and the shot went wild.\" A typical person would assume that this passage suggests that Frank T. had no intention of shooting and injuring someone and that the bullet accidentally hit the neighbor's body; therefore, we conclude that Frank T. did not intentionally hit his neighbor. \n",
    "So the answer is: No\n",
    "\n",
    "Q: How would a typical person answer each of the following questions about causation?\n",
    "Suzy and Billy are working on a project that is very important for our nation's security. The boss tells them both: \"Be sure that you are here at exactly 9 am. It is absolutely essential that you arrive at that time.\" Both Billy and Suzy arrive at 9 am. As it happens, there was a motion detector installed in the room where they arrived. The motion detector was set up to be triggered if at least one person appeared in the room at the same time. So the motion detector went off. Did Billy cause the motion detector to go off?\n",
    "Options:\n",
    "- Yes\n",
    "- No\n",
    "A: Let's think step by step.\n",
    "Here in this question, we are told that the boss ordered them both to arrive at the meeting room at the same time and that the motion detector was set up to be triggered if at least one person appeared in the room at the same time.\" A typical person would assume that the person probably meant to say the detector was set up to be triggered if \"both persons\" appeared in the room at the same time, not at least one person, since otherwise the phrase \"at the same time\" would not make much sense in that sentence. Because the motion detector went off, a typical person would therefore come to the conclusion that both Suzy and Billy triggered the motion detector to go off; hence, Billy did indeed cause the motion detector to go off. \n",
    "So the answer is: Yes\n",
    "\n",
    "Q: How would a typical person answer each of the following questions about causation?\n",
    "George and his sister Lena reunite at their parents' house for Thanksgiving. Whereas George just got into medical school, Lena is unhappy in her marriage and recently lost her job. Over the course of the day, George and Lena get into a number of heated arguments. Later in the afternoon they play a game of darts. They split the first two games, and the third game is close until the end. Who will win comes down to George's last shot. If he hits a high point region, he wins; if he hits a low point region, Lena wins. George thinks of the difficult time Lena is having, and he really wants to let her win. He aims the dart at the low point region. He sets up his shot and the dart lands in the low point region. After his shot, Lena wins the game and is very happy. Did George hit the low point region intentionally?\n",
    "Options:\n",
    "- Yes\n",
    "- No\n",
    "A: Let's think step by step.\n",
    "Here in this question, we are told that \"He aims the dart at the low point region.\" A typical person might therefore think George did intentionally hit the low point region, because he wanted to lift up the spirit of his sister Lena. \n",
    "So the answer is: Yes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "a = re.search(r\"So the answer is (Yes|No)\\.\",answer)\n",
    "if a:\n",
    "    print(a.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import openai\n",
    "import re\n",
    "from openai import OpenAI\n",
    "api_key=''\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "gpt4 = {}\n",
    "for i,q in enumerate(ds['test']['input']):\n",
    "    # Make a request to the OpenAI API\n",
    "    gpt4[i] = {}\n",
    "    print(i)\n",
    "#    if i > 0:\n",
    "#        break\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    #    model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": q,\n",
    "            }\n",
    "        ],\n",
    "        #temperature=0.8,\n",
    "        #max_tokens=512,\n",
    "        #top_p=0.8,\n",
    "        #frequency_penalty=0,\n",
    "        #presence_penalty=0\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    gpt4[i][\"full_answer\"] = answer\n",
    "    #print(answer)\n",
    "    a = re.findall(r\"\\b(Yes|No)\\b\",answer)\n",
    "    if a:\n",
    "        gpt4[i][\"answer\"] = a[-1]\n",
    "    else:\n",
    "        gpt4[i][\"answer\"] = None\n",
    "   \n",
    "with open(\"gpt3_turbo\" + '.pickle', 'wb') as f:\n",
    "        pickle.dump(gpt4, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 187 records, correct: 129, incorrect:58\n",
      "Correct: 68.98%\n",
      "Incorrect: 31.02%\n"
     ]
    }
   ],
   "source": [
    "with open(\"gpt4\" + '.pickle', 'rb') as f:\n",
    "    gp4_loaded = pickle.load(f)\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for idx in gp4_loaded:\n",
    "    if ds[\"test\"][idx][\"target\"] == gp4_loaded[idx][\"answer\"]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "\n",
    "total = correct + incorrect\n",
    "\n",
    "print(f\"There are {total} records, correct: {correct}, incorrect:{incorrect}\")\n",
    "print('Correct: {:0.2f}%'.format(100*correct/total))\n",
    "print('Incorrect: {:0.2f}%'.format(100*incorrect/total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write answers file for inspection\n",
    "i = 0\n",
    "with open(\"./gpt4_dump.txt\",'w') as f:\n",
    "    for key in gp4_loaded:\n",
    "        f.write(gp4_loaded[key][\"full_answer\"] + \"\\n\")\n",
    "        f.write(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"+\"\\n\")\n",
    "        f.write(gp4_loaded[key][\"answer\"]+\"\\n\")\n",
    "        f.write(\"##############################\"+\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
